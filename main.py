import sys
import re
import os
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, AIMessageChunk
from graph import app

def clean_filename(topic):
    """å°† topic è½¬æ¢ä¸ºåˆæ³•çš„æ–‡ä»¶å"""
    # å°†éå­—æ¯æ•°å­—çš„å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå»æ‰å¤šä½™ä¸‹åˆ’çº¿
    filename = re.sub(r'[^\w\s-]', '', topic).strip().lower()
    return re.sub(r'[-\s]+', '_', filename)


def main():
    if len(sys.argv) < 2:
        print("Usage: python main.py <topic>")
        sys.exit(1)
    
    topic = " ".join(sys.argv[1:])
    
    print(f"--- Starting Search Agent for: {topic} ---")
    
    system_prompt = (
        "You are a smart research assistant. "
        "Your goal is to research the user's topic using the web search and visit_page tools. "
        "1. Use `search_web` to find relevant pages. "
        "2. Use `visit_page` to read detailed content from promising URLs. "
        "3. Synthesize information into a comprehensive Markdown report. "
        "The document should have a clear title, headings, and bullet points. "
        "è¯·ç”¨ä¸­æ–‡å›ç­”"
    )
    
    first_input = {"writer_messages": [
        SystemMessage(content=system_prompt),
        HumanMessage(content=topic)
    ]}

    # ç”¨äºå­˜å‚¨æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹,save as local markdown file
    final_content = ""
    

    # stream_mode="values"ï¼š
    # for event in app.stream(inputs, stream_mode="values", config={"recursion_limit": 50}):
    #     message = event["messages"][-1]
    #     message.pretty_print()

    #     # å®æ—¶æ›´æ–° final_contentï¼Œå¦‚æœæ˜¯ Writer çš„æ¶ˆæ¯ä¸”æœ‰å†…å®¹ï¼Œå°±è®°å½•ä¸‹æ¥
    #     if isinstance(message, AIMessage) and message.content and getattr(message, 'name', None) == 'writer':
    #         final_content = message.content


    # stream_mode="updates"ï¼š
    for event in app.stream(first_input, stream_mode="updates", config={"recursion_limit": 80}):
        for node_name, node_val in event.items():
            if "writer_messages" in node_val and node_val["writer_messages"]:
                message = node_val["writer_messages"][-1]
                message.pretty_print()
            elif "critic_messages" in node_val and node_val["critic_messages"]:
                message = node_val["critic_messages"][-1]
                message.pretty_print()
                
            # Update draft if present
            if "current_draft" in node_val and node_val["current_draft"]:
                final_content = node_val["current_draft"]
    

    # stream_mode="messages"
        # --- çŠ¶æ€è¿½è¸ªå˜é‡ ---
    # ç”¨äºç¼“å­˜æ‹¼å‡‘çš„æ¶ˆæ¯ï¼š key=message_id, value=full_text_so_far
    # message_buffer = {} 
    # # è®°å½•æœ€åä¸€æ¡æ¥è‡ª writer èŠ‚ç‚¹çš„æ¶ˆæ¯ ID
    # last_writer_msg_id = None
    # # è®°å½•å½“å‰æ­£åœ¨è¾“å‡ºçš„èŠ‚ç‚¹åç§°ï¼Œç”¨äºæ‰“å° Header
    # current_node = None 
    
    # # æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ stream_mode="messages"
    # for msg_chunk, metadata in app.stream(inputs, stream_mode="messages", config={"recursion_limit": 50}):
        
    #     # metadata åŒ…å«äº†å½“å‰ Token æ¥è‡ªå“ªä¸ªèŠ‚ç‚¹ï¼Œä¾‹å¦‚ {'langgraph_node': 'writer', ...}
    #     node_name = metadata.get("langgraph_node")

    #     # --- 1. æ‰“å°èŠ‚ç‚¹å½’å± Header (ç±»ä¼¼ pretty_print çš„æ•ˆæœ) ---
    #     if node_name != current_node:
    #         # æ ¹æ®ä¸åŒè§’è‰²æ‰“å°ä¸åŒçš„æ ‡é¢˜
    #         header_icon = "ğŸ¤–"
    #         role_name = node_name.upper()  
    #         if node_name == "writer":
    #             header_icon = "âœï¸âœï¸âœï¸âœï¸âœï¸âœï¸âœï¸"
    #             role_name = "WRITER (Thinking/Writing)"
    #         elif node_name == "critic":
    #             header_icon = "ğŸ•µï¸ğŸ•µï¸ğŸ•µï¸ğŸ•µï¸ğŸ•µï¸ğŸ•µï¸ğŸ•µï¸"
    #             role_name = "CRITIC (Reviewing)"
    #         elif node_name == "tools":
    #             header_icon = "ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸"
    #             role_name = "TOOL OUTPUT"
    #         # æ‰“å°åˆ†éš”çº¿å’Œè§’è‰²å
    #         print(f"\n\n{header_icon} --- [ {role_name} ] ---\n")
    #         current_node = node_name
        
    #     # 1. å®æ—¶æ‰“å°é€»è¾‘ (æ‰“å­—æœºæ•ˆæœ)
    #     # æˆ‘ä»¬åªæ‰“å°æœ‰å†…å®¹çš„ chunkï¼Œä¸”ä¸ºäº†ç¾è§‚ï¼Œå¯ä»¥åªæ‰“å° writer å’Œ critic çš„å‘è¨€
    #     # æƒ…å†µ A: æ–‡æœ¬å†…å®¹ (Writer/Critic çš„å›å¤ï¼Œæˆ– Tool çš„æœç´¢ç»“æœ)
    #     if msg_chunk.content:
    #         print(msg_chunk.content, end="", flush=True)
        
    #     # æƒ…å†µ B: å·¥å…·è°ƒç”¨è¯·æ±‚ (Writer æ­£åœ¨æ„é€ å‚æ•°å»è°ƒç”¨å·¥å…·)
    #     # è¿™æ—¶ content é€šå¸¸ä¸ºç©ºï¼Œä½†åœ¨ tool_call_chunks é‡Œæœ‰æ•°æ®
    #     if hasattr(msg_chunk, 'tool_call_chunks') and msg_chunk.tool_call_chunks:
    #         # ç®€å•å¯è§†åŒ–ï¼šæ‰“å°å‚æ•°ç‰‡æ®µï¼Œè®©ç”¨æˆ·çŸ¥é“ Agent æ­£åœ¨å°è¯•æ“ä½œ
    #         for chunk in msg_chunk.tool_call_chunks:
    #             # æ‰“å°å·¥å…·åæˆ–å‚æ•°ç‰‡æ®µï¼ˆé€šå¸¸æ˜¯ JSON ç¢ç‰‡ï¼‰
    #             if chunk.get("name"):
    #                 print(f"\n[Call Tool: {chunk['name']}] args: ", end="", flush=True)
    #             if chunk.get("args"):
    #                 print(chunk["args"], end="", flush=True)
        
    #     # 2. å†…å®¹æ•è·é€»è¾‘ (ä¸ºäº†ä¿å­˜æ–‡ä»¶)
    #     # æˆ‘ä»¬åªå…³å¿ƒ writer ç”Ÿæˆçš„å†…å®¹ä½œä¸ºæœ€ç»ˆæŠ¥å‘Š
    #     # æ³¨æ„ï¼šwriter å¯èƒ½ä¼šå¤šæ¬¡å‘è¨€ï¼ˆæ¯”å¦‚å…ˆè¯´â€œæˆ‘è¦æœç´¢...â€ï¼Œæœ€åæ‰è¯´â€œè¿™æ˜¯æŠ¥å‘Š...â€ï¼‰
    #     # æˆ‘ä»¬é€šè¿‡ä¸æ–­æ›´æ–° last_writer_msg_idï¼Œæœ€ç»ˆä¿ç•™ writer è¯´çš„â€œæœ€åä¸€æ®µè¯â€
    #     if node_name == "writer" and isinstance(msg_chunk, AIMessageChunk):
    #         # è·å–æ¶ˆæ¯çš„å”¯ä¸€ ID (LangChain ä¼šè‡ªåŠ¨ç”Ÿæˆï¼Œæˆ–è€…æµå¼ä¸­ä¿æŒä¸€è‡´)
    #         msg_id = msg_chunk.id 
            
    #         # å¦‚æœæ²¡æœ‰ ID (æå°‘æ•°æƒ…å†µ)ï¼Œç”¨ "temp" ä»£æ›¿ï¼Œä½†è¿™å¯èƒ½å¯¼è‡´è¦†ç›–é—®é¢˜
    #         if not msg_id: 
    #             msg_id = "temp_writer_id"

    #         # åˆå§‹åŒ–æˆ–è¿½åŠ å†…å®¹
    #         if msg_id not in message_buffer:
    #             message_buffer[msg_id] = ""
            
    #         # åªæœ‰å½“ chunk æœ‰æ–‡æœ¬å†…å®¹æ—¶æ‰è¿½åŠ  (å¿½ç•¥ tool_call_chunks)
    #         if msg_chunk.content:
    #             message_buffer[msg_id] += msg_chunk.content
    #             # æ ‡è®°è¿™æ˜¯ Writer å‘å‡ºçš„æœ€æ–°ä¸€æ¡æ–‡æœ¬æ¶ˆæ¯
    #             last_writer_msg_id = msg_id

    # # --- æå–æœ€ç»ˆå†…å®¹ ---
    # if last_writer_msg_id and last_writer_msg_id in message_buffer:
    #     final_content = message_buffer[last_writer_msg_id]
                

    print("\n\n--- Stream finished ---")
    # --- ä¿å­˜æ–‡ä»¶é€»è¾‘ ---
    if final_content:
        # 1. åˆ›å»º output æ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        output_dir = "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # 2. ç”Ÿæˆæ–‡ä»¶å
        filename = f"{clean_filename(topic)}.md"
        filepath = os.path.join(output_dir, filename)
        
        # 3. å†™å…¥æ–‡ä»¶
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(final_content)
            print(f"\nâœ… Document saved successfully to: {filepath}")
        except Exception as e:
            print(f"\nâŒ Failed to save document: {e}")
    else:
        print("\nâš ï¸ No content was generated to save.")


if __name__ == "__main__":
    main()


'''
Step 1: å¯åŠ¨ä¸ç³»ç»Ÿæç¤º (main.py)
ç¨‹åºå¼€å§‹ï¼Œæ„å»ºåˆå§‹è¾“å…¥ï¼š
    SystemMessage: "ä½ æ˜¯ç ”ç©¶åŠ©ç†...è¯·æœç´¢å¹¶æ€»ç»“..." (è®¾å®šäº† Agent çš„äººè®¾å’Œç›®æ ‡)ã€‚
    HumanMessage: "The future of quantum computing"ã€‚
è°ƒç”¨ app.stream(inputs) å¼€å§‹å›¾çš„æ‰§è¡Œã€‚
Step 2: ç¬¬ä¸€è½®æ€è€ƒ (è¿›å…¥ graph.py çš„ agent èŠ‚ç‚¹)
    Input: System Prompt + User Queryã€‚
    LLM å¤„ç†: LLM å‘ç°è‡ªå·±ä¸çŸ¥é“é‡å­è®¡ç®—çš„æœ€æ–°æœªæ¥ï¼Œä¸”è¿™éœ€è¦å¤–éƒ¨çŸ¥è¯†ã€‚
    LLM Output: è¿”å›ä¸€ä¸ª AIMessageï¼Œå†…å®¹ä¸ºç©ºï¼Œä½†åŒ…å« tool_calls: name='search_web', args={'query': 'future of quantum computing'}ã€‚
    Edge åˆ¤æ–­: tools_condition æ£€æµ‹åˆ° tool_callsï¼Œå°†æµå‘æŒ‡å¼•åˆ° tools èŠ‚ç‚¹ã€‚
Step 3: æ‰§è¡Œå·¥å…· (è¿›å…¥ graph.py çš„ tools èŠ‚ç‚¹)
    Input: ä¸Šä¸€æ­¥çš„ AIMessage (åŒ…å«è°ƒç”¨æŒ‡ä»¤)ã€‚
    Action: ToolNode è§£ææŒ‡ä»¤ï¼ŒçœŸæ­£æ‰§è¡Œ search_web("future of quantum computing")ã€‚
    DDGS: è®¿é—® DuckDuckGoï¼ŒæŠ“å– Top 5 ç»“æœã€‚
    Output: ç”Ÿæˆä¸€ä¸ª ToolMessageï¼Œå†…å®¹æ˜¯æœç´¢åˆ°çš„ JSON å­—ç¬¦ä¸²/æ–‡æœ¬ã€‚
    Edge: å¼ºåˆ¶æµå› agent èŠ‚ç‚¹ã€‚
Step 4: ç¬¬äºŒè½®æ€è€ƒ (å›åˆ° agent èŠ‚ç‚¹)
Input (æ­¤æ—¶çš„çŠ¶æ€):
    [0] SystemMessage
    [1] HumanMessage (User input)
    [2] AIMessage (I want to search...)
    [3] ToolMessage (Here are the search results...)
LLM å¤„ç†: LLM é˜…è¯»äº† [3] ä¸­çš„æœç´¢ç»“æœã€‚
    æƒ…å†µ A: ä¿¡æ¯ä¸å¤Ÿ -> LLM å†æ¬¡ç”Ÿæˆ tool_calls (æœç´¢å¦ä¸€ä¸ªå…³é”®è¯)ï¼Œå¾ªç¯å› Step 3ã€‚
    æƒ…å†µ B: ä¿¡æ¯è¶³å¤Ÿ -> LLM å¼€å§‹æ ¹æ® Prompt çš„è¦æ±‚ï¼ˆæ’°å†™ Markdown æ–‡æ¡£ï¼‰è¿›è¡Œç»¼åˆã€‚
LLM Output: è¿”å›ä¸€ä¸ª AIMessageï¼Œå†…å®¹æ˜¯æœ€ç»ˆçš„ Markdown æ€»ç»“æ–‡ç« ã€‚ä¸åŒ…å« tool_callsã€‚
Edge åˆ¤æ–­: tools_condition å‘ç°æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè·¯ç”±åˆ° ENDã€‚
Step 5: è¾“å‡ºç»“æœ (main.py)
    app.stream ä¹Ÿæ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ã€‚åœ¨ä¸Šè¿°æ¯ä¸€ä¸ª Step å®Œæˆæ—¶ï¼Œmain.py ä¸­çš„å¾ªç¯éƒ½ä¼šæ”¶åˆ°æ›´æ–°çš„ eventã€‚
'''